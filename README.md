# sign-language_CNN
Convolutional neural network which classifies images as letters in sign language.

In this project I worked on a multi-class classification problem. Here I'm using the [Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist) dataset, which contains 28x28 images of hands depicting the 26 letters of the english alphabet. 

![image](https://github.com/HelenLit/sign-language_CNN/assets/108334668/c7a862e4-321a-4a7a-a9e9-415b1bf61c06)

**loss: 0.4418 - accuracy: 0.8629 - val_loss: 0.0977 - val_accuracy: 0.9699**

## Model architecture is pretty simple here:

![image](https://github.com/HelenLit/sign-language_CNN/assets/108334668/70d66ff8-7699-4fad-a08c-eb537a462686)

## Accuracy and loss on both training and validation:
![image](https://github.com/HelenLit/sign-language_CNN/assets/108334668/93c29dfd-0c63-4fae-9f11-182aae00280f)
![image](https://github.com/HelenLit/sign-language_CNN/assets/108334668/d6a9276c-4d09-4c8b-9853-caf2c998fd23)





